{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_size：x的特征维度\n",
    "hidden_size：隐藏层的特征维度\n",
    "num_layers：lstm隐层的层数，默认为1\n",
    "bias：False则bih=0和bhh=0. 默认为True\n",
    "batch_first：True则输入输出的数据格式为 (batch, seq, feature)\n",
    "dropout：除最后一层，每一层的输出都进行dropout，默认为: 0\n",
    "bidirectional：True则为双向lstm默认为False\n",
    "输入：input, (h0, c0)\n",
    "输出：output, (hn,cn)\n",
    "输入数据格式：\n",
    "input(seq_len, batch, input_size)\n",
    "h0(num_layers * num_directions, batch, hidden_size)\n",
    "c0(num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "输出数据格式：\n",
    "output(seq_len, batch, hidden_size * num_directions)\n",
    "hn(num_layers * num_directions, batch, hidden_size)\n",
    "cn(num_layers * num_directions, batch, hidden_size)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,in_dim,hidden_dim,n_layer,n_class,bidirectional=False):\n",
    "        super(RNN,self).__init__()\n",
    "        self.n_layer = n_layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(in_dim,hidden_dim,n_layer,bidirectional=bidirectional,batch_first=True)\n",
    "        self.direction = 2 if bidirectional else 1\n",
    "        self.classifier = nn.Linear(hidden_dim * self.direction,n_class)\n",
    "    def forward(self,x):\n",
    "        out,(h_n,c_n) = self.lstm(x)\n",
    "        res = self.classifier(out)\n",
    "        print(out.shape,h_n.shape,c_n.shape,res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 40]) torch.Size([2, 5, 20]) torch.Size([2, 5, 20]) torch.Size([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(10,20,1,3,True)\n",
    "x = torch.randn((5,3,10))\n",
    "rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "#in_channels(int) – 输入信号的通道。在文本分类中，即为词向量的维度；图像中为RGB三通道。\n",
    "#out_channels(int) – 卷积产生的通道。有多少个out_channels，就需要多少个1维卷积\n",
    "#kernel_size(int or tuple) - 卷积核的尺寸，卷积核的大小\n",
    "#stride(int or tuple, optional) - 卷积步长\n",
    "#padding (int or tuple, optional)- 输入的每一条边补充0的层数\n",
    "#dilation(int or tuple, `optional``) – 卷积核元素之间的间距\n",
    "#groups(int, optional) – 从输入通道到输出通道的阻塞连接数\n",
    "#bias(bool, optional) - 如果bias=True，添加偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size,num_class,kernel_num=100,kernel_sizes=(2,3,4),drop_out=0.5,is_train=True):\n",
    "        super(TextCNN,self).__init__()\n",
    "        self.emd = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1,kernel_num,(kernel_size,embedding_size)) for kernel_size in kernel_sizes])\n",
    "        self.drop_out = nn.Dropout(drop_out)\n",
    "        self.classifier = nn.Linear(len(kernel_sizes) * kernel_num,num_class)\n",
    "        self.is_train = is_train\n",
    "    def forward(self,x):\n",
    "        x = self.emd(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        print(x.size())\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        print(x[0].shape,x[1].shape)\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "             i in x] #[(N,Co), ...]*len(Ks)\n",
    "        print(x[0].shape,x[1].shape)\n",
    "        concated = torch.cat(x,1)\n",
    "        if self.is_train:\n",
    "            concated = self.drop_out(concated)\n",
    "        logits = self.classifier(concated)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "textCnn = TextCNN(100,50,5)\n",
    "seq = [[1,2,3,4,5],[5,4,3,2,1],[6,7,8,9,7],[7,9,7,8,6]]\n",
    "seqs = [seq for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "torch.Size([4, 1, 5, 50])\n",
      "torch.Size([4, 100, 4]) torch.Size([4, 100, 3])\n",
      "torch.Size([4, 100]) torch.Size([4, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0302, -0.7218, -0.7472, -0.1455,  1.8735],\n",
       "        [ 0.0666, -0.3853, -0.3979, -0.1382,  0.5298],\n",
       "        [-0.5417, -0.3284, -0.4055,  0.3855,  1.2028],\n",
       "        [ 0.0988, -0.0505, -0.2216,  0.0774,  0.4394]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = torch.tensor(seqs,dtype=int)\n",
    "print(seqs[0].shape)\n",
    "textCnn(seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor",
   "language": "python",
   "name": "tor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
